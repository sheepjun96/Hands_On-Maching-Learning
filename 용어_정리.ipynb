{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMSHGWcI5gyYZkKQcZ4UFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheepjun96/Hands_On-Maching-Learning/blob/main/%EC%9A%A9%EC%96%B4_%EC%A0%95%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1장 용어 정리"
      ],
      "metadata": {
        "id": "5mebfq-yjNFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 마이닝**: 대용량의 데이터를 분석하여 숨겨진 패턴을 발견하는 것\n",
        "\n",
        "**특성 추출**: 차원 축소의 한 방법으로 상관관계가 있는 여러 특성을 하나로 합치는 것\n",
        "\n",
        "**이상치 탐지**: 학습 알고리즘에 주입하기 전에 데이터셋에서 이상한 값을 자동으로 제거하는 것\n",
        "\n",
        "**특이치 탐지**: 훈련 세트에 있는 모든 샘플과 달라 보이는 새로운 샘플을 탐지\n",
        "\n",
        "**연관 규칙 학습**: 대량의 데이터에서 특성 간의 흥미로운 관계를 찾는다.\n",
        "\n",
        "**자기 지도 학습**: 레이블이 전혀 없는 데이터셋에서 레이블이 완전히 부여된 데이터셋을 생성하는 것\n",
        "\n",
        "**학습률**: 변화하는 데이터에 얼마나 빠르게 적응할 것인지에 대한 파라미터\n",
        "\n",
        "**사례 기반 학습**: 시스템이 훈련 샘플을 기억하며, 유사도 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화\n",
        "\n",
        "**모델 기반 학습**: 샘플들의 모델을 만들어 예측에 사용\n",
        "\n",
        "모델이 얼마나 좋은지를 측정하는 **효용함수 or 적합도 함수**, 나쁜지를 측정하는 **비용 함수**"
      ],
      "metadata": {
        "id": "YEAUchzNeSSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2장 용어 정리"
      ],
      "metadata": {
        "id": "VDeflX8bjUiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 스누핑**: 테스트 세트로 일반화 오차를 추정하면 매우 낙관적인 추정으로 기대한 성능이 나오지 않는 현상\n",
        "\n",
        "**계층적 샘플링**: 미국 인구의 51.1%가 여성이고, 48.9%가 남성이라면, 설문조사의 샘플에도 이 비율을 유지해야 한다.\n",
        "\n",
        "**특성 스케일링**: 숫자 특성들의 스케일을 변화해 모든 특성의 범위를 같게 만들어준다. min-max 스케일링(정규화)와 표준화가 있다.\n",
        "\n",
        "> 다만 이런 방법은 대부분의 값을 작은 범위로 압축한다. 이런 방법말고 특성을 스케일링하기 전에 두꺼운 꼬리를 줄이도록 데이터를 먼저 변환하고 분포가 대략적으로 대칭이 되도록 만들어야 한다.\n",
        "\n",
        "**멱법칙 분포**: 특성 분포의 꼬리가 아주 길고 두껍다면 특성을 로그값으로 바꾸어 만든다.\n",
        "\n",
        "**멀티모달 분포**: 모드라 부르는 정점이 두 개 이상 나타나는 분포\n",
        "\n",
        "**k-폴드 교차 검증**: 훈련 세트를 폴드라 불린느 중복되지 않은 k개의 서브셋으로 랜덤으로 분할한다. 그런 다음 결정 트리 모델을 k번 훈련하고 평가하는데, 매번 다른 폴드를 선택해 평가에 사용한다. 그래서 k개의 평가 점수가 담긴 배열이 결과가 된다.\n"
      ],
      "metadata": {
        "id": "MVXqyl89jim1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3장 용어 정리"
      ],
      "metadata": {
        "id": "iOcQ2bV57kqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**불균형한 데이터셋**: 어떤 클래스가 다른 것보다 월등히 많은 경우\n",
        "\n",
        "[53892(TN),   687(FP)]\n",
        "\n",
        "[1891(FN),  3530(TP)]\n",
        "\n",
        "* 오차 행렬의 행은 실제 클래스를 나타내고, 열은 예측한 클래스를 나타낸다.\n",
        "\n",
        "* 이 행렬의 첫 번째 행은 '5 아님' 이미지(음성 클래스)에 대한 것으로, 53892개를 '5 아님'으로 정확하게 분류했고(진짜 음성), 나머지 687개는 '5'라고 잘못 분류했다.(거짓 양성 또는 1종 오류)\n",
        "\n",
        "* 두 번째 행은 '5' 이미지(양성 클래스)에 대한 것으로, 1891개를 '5 아님'으로 잘못 분류했고(거짓 음성 또는 2종 오류) 나머지 3530개를 정확히 '5'라고 분류했다(진짜 양성).\n",
        "\n",
        "* 완벽한 분류기라면 진짜 양성과 진짜 음성만 가지고 있을 것이므로 오차 행렬의 주대각선만 0이 아닌 값이 된다.\n",
        "\n",
        "**정밀도**: 양성 예측의 정확도\n",
        "* TP / (TP + FP), TP는 진짜 양성의 수, FP는 거짓 양성의 수\n",
        "\n",
        "**재현율**: 정확하게 감지한 양성 샘플의 비율\n",
        "* TP / (TP + FN), FN은 거짓 음성의 수\n",
        "\n",
        "**F1 점수**: 2/(1/정밀도 + 1/재현율) = 2 x (정밀도 x 재현율) / (정밀도 + 재현율)\n",
        "\n",
        "**정밀도/재현율 트레이드오프**: 정밀도와 재현율의 반비례 관계\n",
        "\n",
        "**ROC 곡선**: 수신기 조작 특성 곡선은 정밀도에 대한 재현율 곡선이 아니라 거짓 양성 비율(FPR)에 대한 진짜 양성 비율(TPR, 재현율의 다른 이름)의 곡선이다.\n",
        "\n",
        "> FPR은 양성으로 잘못 분류된 음성 샘플의 비율이다. 이는 1에서 음성으로 정확하게 분류한 음성 샘플의 비율인 진짜 음성 비율(TNR)을 뺀 값이다. TNR을 특이도라고도 한다. 그러므로 ROC 곡선은 민감도(재현율)에 대한 1-특이도 그래프이다.\n",
        "\n",
        "> FPR = FP /(FP+TN) = 1 - TN/(FP + TN) = 1 - TNR\n",
        "\n",
        "**곡선 아래의 면적(AUC)**을 측정해 분류기들을 비교할 수 있다. 완벽한 분류기는 ROC의 AUC가 1이고, 완전한 랜덤 분류기는 0.5이다.\n",
        "\n",
        "다중 분류에서 이미지를 분류할 때 각 분류기의 결정 점수 중에서 가장 높은 것을 클래스로 선택하는 것을 OvR 전략 또는 OvA라고 한다.\n",
        "\n",
        "0과 1 구별, 0과 2 구별과 같이 각 숫자의 조합마다 이진 분류기를 훈련시키는 것을 OvO 전략이라고 한다. 이는 클래스 N개에서 분류기 N(N-1) / 2개가 필요하다.\n",
        "\n",
        "**다중 레이블 분류**: 여러 개의 이진 꼬리표를 출력하는 분류 시스템\n",
        "\n"
      ],
      "metadata": {
        "id": "ATlg4fq_7nLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 애플리케이션 사례\n",
        "\n",
        "1. **생산 라인에서 제품 이미지를 분석해 자동으로 분류하기**: 이미지 분류 작업,\n",
        "일반적으로 합성곱 신경망이나 트랜스포머를 사용\n",
        "\n",
        "2. **뇌를 스캔하여 종양 진단하기**: 시맨틱 분할 작업, CNN이나 트랜스포머를 사용해 이미지의 각 픽셀을 분류\n",
        "\n",
        "3. **자동으로 뉴스 기사 분류하기**: 자연어 처리 NLP작업, RNN, CNN을 사용하기도 하지만 트랜스포머가 더 잘 처리함\n",
        "\n",
        "4. **토큰 포럼에서 부정적인 코멘트를 자동으로 구분하기 & 긴 문서를 자동으로 요약하기**: NLP도구를 사용\n",
        "\n",
        "5. **여러 가지 성과 자료를 바탕으로 회사의 내년도 수익 예측하기**: 회귀 작업, 선형 회귀나 다항 회귀 모델, 회귀 서포트 벡터머신, 회귀 랜덤 포레스트, 인공 신경망과 같은 회귀 모델 사용. 과거 성과 데이터를 시퀀스로 고려하고 싶다면 RNN, CNN 또는 트랜스포머를 사용\n",
        "\n",
        "6. **음성 명령에 반응하는 앱 만들기**: 오디오 샘플을 처리해야 한다. 길고 복잡한 시퀀스이므로 일반적으로 RNN, CNN 또는 트랜스포머를 사용한다.\n",
        "\n",
        "7. **신용카드 부정거래 감지하기**: 이상치 탐지 작업, 아이솔레이션 포레스트, 가우스 혼합 모델이나 오토인코더를 사용\n",
        "\n",
        "8. **구매 이력을 기반으로 고객을 나누고 각 집합마다 다른 마케팅 전략을 계획하기**: 군집 작업, k-평균, DBSCAN 등을 사용\n",
        "\n",
        "9. **과거 구매 이력을 기반으로 관심을 가질 수 있는 상품 추천**: 추천 시스템으로 인공 신경망에 주입\n",
        "\n",
        "10. **지능형 게임 봇 만들기**: 강화학습으로 만듦"
      ],
      "metadata": {
        "id": "ndYrcaOdemej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 스케일링의 종류\n",
        "1. StandardScaler\n",
        "\n",
        ">평균=0, 표준편차=1로 조정해서 모든 특성이 같은 크기를 갖게 한다.\n",
        "\n",
        "\n",
        "\n",
        "2. MinMaxScaler\n",
        "\n",
        "> 최대값=1, 최소값=0으로 조정, 아웃라이어에 취약\n",
        "\n",
        "\n",
        "\n",
        "3. RobustScaler\n",
        "\n",
        "> 중앙값=0, IQR(1분위~3분위값)=1로 조정, 아웃라이어 영향을 최소화하며 정규분포보다 더 넓게 분포\n",
        "\n",
        "\n",
        "\n",
        "4. MaxAbsScaler\n",
        "\n",
        "> 0을 기준으로 절대값이 가장 큰 수가 1 또는 -1이 되도록 조정, 양수 데이터로만 구성된 데이터셋에서는 아웃라이어에 민감\n",
        "\n",
        "\n",
        "\n",
        "데이터 스케일링을 하는 이유가 아웃라이어의 영향을 최소화하는 것이기 때문에 보통은 이상치 영향을 가장 적게 받는 StandardScaler 혹은 RobustScaler를 주로 사용한다. 모두 사이킷런에서 모듈을 제공한다."
      ],
      "metadata": {
        "id": "56eUoZN7D8Kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랜덤 서치가 그리드 서치보다 좋은 점\n",
        "\n",
        "* 하이퍼파라미터 값이 연속적이면 랜덤 서치를 1000번 실행했을 때 각 하이퍼파라미터마다 1000개의 다른 값을 탐색한다. 반면, 그리드 서치는 하이퍼파라미터에 대해 나열한 몇 개의 값만을 탐색한다.\n",
        "\n",
        "* 어떤 하이퍼파라미터가 성능 면에서 큰 차이를 만들지 못하지만 이 사실을 모를 때, 10개의 가능한 값이 있을 때 그리드 서치에 추가하면 훈련이 10배 더 오래 걸리지만, 랜덤 서치에 추가하면 탐색 시간이 더 늘어나지 않는다.\n",
        "\n",
        "* 6개의 하이퍼파라미터에 대해 각각 10개의 값을 탐색하면 그리드 서치는 백만 번 모델을 훈련해야 하지만 랜덤 서치는 지정한 반복 횟수만큼 실행할 수 있다."
      ],
      "metadata": {
        "id": "0ajmNqa9oTr7"
      }
    }
  ]
}